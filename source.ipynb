{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import timeit\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tkinter.font as tkFont\n",
    "import torch \n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageGrab, Image, ImageOps, EpsImagePlugin\n",
    "from skimage.io import imread,imshow\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = transforms.Compose([transforms.Resize((128,128))])\n",
    "\n",
    "def resize_image(img):\n",
    "    \n",
    "    img = p(img)\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "def crop_image(img, tol=0):\n",
    "    \n",
    "    mask = img <= 0\n",
    "    coords = np.argwhere(mask)\n",
    "    x0, y0 = coords.min(axis=0)\n",
    "    x1, y1 = coords.max(axis=0) + 1\n",
    "    cropped = img[x0:x1, y0:y1]\n",
    "    return cropped\n",
    "\n",
    "def slice_img(imarr):\n",
    "    l= []\n",
    "    for i in range(0, len(imarr), int(len(imarr)/4)):\n",
    "        for j in range(0, len(imarr), int(len(imarr)/4)):\n",
    "            l.append(imarr[0+i: int(len(imarr)/4)+i, 0+j: int(len(imarr)/4)+j])\n",
    "    return l\n",
    "\n",
    "def nb_pixels(block):\n",
    "    i=0.0\n",
    "    for a in block:\n",
    "        for b in a :\n",
    "            if b!=1.0:\n",
    "                i += 1.0\n",
    "    return i\n",
    "\n",
    "def linReg(b):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(len(b)):\n",
    "        for j in range(len(b)):\n",
    "            if b[i,j]!=1.0:\n",
    "                x.append(i)\n",
    "                y.append(j)\n",
    "    x.reverse()\n",
    "    if nb_pixels(b)!=0.0:\n",
    "        model = LinearRegression().fit(np.array(x).reshape((-1, 1)), np.array(y))\n",
    "        return (model.coef_[0], model.intercept_)\n",
    "    else : \n",
    "        return (0.0, 0.0)\n",
    "\n",
    "def feature_extraction(img):\n",
    "    plt.imsave('ima.png', img, cmap='gray')\n",
    "    img1 = Image.open('ima.png').convert('RGB')\n",
    "    img1 = ImageOps.invert(img1)\n",
    "    imarr = resize_image(img1)\n",
    "\n",
    "    for i in range(len(imarr)) :\n",
    "        for j in range(len(imarr[i])):\n",
    "            if imarr[i][j]!=1.0:\n",
    "                imarr[i][j]=0.0\n",
    "\n",
    "    imarr = crop_image(imarr)\n",
    "\n",
    "    plt.imsave('cropped.png', imarr,cmap='gray')\n",
    "\n",
    "    cropped_image = Image.open('cropped.png')\n",
    "\n",
    "    crop_arr = resize_image(cropped_image)\n",
    "\n",
    "    for i in range(len(crop_arr)) :\n",
    "        for j in range(len(crop_arr[i])):\n",
    "            if crop_arr[i][j]!=1.0:\n",
    "                crop_arr[i][j] = 0.0\n",
    "\n",
    "    l = slice_img(crop_arr)\n",
    "    n = 0.0\n",
    "    for b in l :\n",
    "        n += nb_pixels(b)\n",
    "    a = []\n",
    "    for b in l :\n",
    "        a.append(nb_pixels(b)/n)\n",
    "        a.append((2*linReg(b)[1])/(1+linReg(b)[1]**2))\n",
    "        a.append((1-linReg(b)[1]**2)/(1+linReg(b)[1]**2))\n",
    "    a = torch.tensor(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000  :  Temps restant : 0.002262590000007947 minn"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_dataset = datasets.MNIST(root='./data' ,train=True,download=True,transform=None)\n",
    "test_dataset = datasets.MNIST(root='./data' ,train=False,download=True,transform=None)\n",
    "\n",
    "donnees_apprentissage,donnees_validation = train_test_split(training_dataset.data.numpy(), test_size=0.16, random_state=42)\n",
    "label_apprentissage,label_validation = train_test_split(training_dataset.targets.numpy(), test_size=0.16, random_state=42)\n",
    "label_test = test_dataset.targets\n",
    "\n",
    "fe_app = []\n",
    "for i in range(len(donnees_apprentissage)):\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    fe_app.append(feature_extraction(donnees_apprentissage[i]))\n",
    "    stop = timeit.default_timer()\n",
    "    time_left = (stop-start)/60\n",
    "    sys.stdout.write('\\r'+str(i+1)+'/'+str(len(donnees_apprentissage))+'  :  Temps restant : '+str(time_left*len(donnees_apprentissage)-i*time_left)+' min')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "fe_val = []\n",
    "for i in range(len(donnees_validation)):\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    fe_val.append(feature_extraction(donnees_validation[i]))\n",
    "    stop = timeit.default_timer()\n",
    "    time_left = (stop-start)/60\n",
    "    sys.stdout.write('\\r'+str(i+1)+'/'+str(len(donnees_validation))+'  :  Temps restant : '+str(time_left*len(donnees_validation)-i*time_left)+' min')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "fe_test = []\n",
    "for i in range(len(test_dataset.data)):\n",
    "    start = timeit.default_timer()\n",
    "    fe_test.append(feature_extraction(test_dataset.data[i]))\n",
    "    stop = timeit.default_timer()\n",
    "    time_left = (stop-start)/60\n",
    "    sys.stdout.write('\\r'+str(i+1)+'/'+str(len(test_dataset.data))+'  :  Temps restant : '+str(time_left*len(test_dataset.data)-i*time_left)+' min')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"features_app\", \"wb\") as file:\n",
    "    pickle.dump(fe_app, file)\n",
    "    \n",
    "with open(\"features_val\", \"wb\") as file:\n",
    "    pickle.dump(fe_val, file)\n",
    "\n",
    "with open(\"features_test\", \"wb\") as file:\n",
    "    pickle.dump(fe_test, file)\n",
    "    \n",
    "with open(\"targets_app\", \"wb\") as file:\n",
    "    pickle.dump(label_apprentissage, file)\n",
    "\n",
    "with open(\"targets_val\", \"wb\") as file:\n",
    "    pickle.dump(label_validation, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,data,targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.data[idx],self.targets[idx])\n",
    "    def __len__(self):  \n",
    "        return len(self.targets)\n",
    "\n",
    "my_training_dataset = MyDataset(fe_app,label_apprentissage)\n",
    "my_test_dataset = MyDataset(fe_test,label_test)\n",
    "my_validation_dataset = MyDataset(fe_val,label_validation)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(my_training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(my_test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(my_validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "class myNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(48, 100)\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "myModel = myNN()\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(myModel.parameters(), lr=0.001)\n",
    "n_epochs = 100\n",
    "\n",
    "from torch.autograd import Variable\n",
    "for epoch in range(n_epochs):\n",
    "    myModel.train()\n",
    "    \n",
    "    t_cost= 0.0\n",
    "    \n",
    "    for i,(inputs,labels) in enumerate(train_loader):\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        outputs = myModel(inputs)\n",
    "        cout = loss(outputs,labels.long())\n",
    "        # Backpropagation: \n",
    "        # RÃ©initialiser l'optimiseur\n",
    "        opt.zero_grad()\n",
    "        cout.backward()\n",
    "        opt.step()\n",
    "        t_cost += cout\n",
    "    t_cout_moy = t_cost/(len(train_loader))\n",
    "    v_cost= 0.0\n",
    "    n_prev = 0\n",
    "    myModel.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_losss =0\n",
    "        for i, data in enumerate(validation_loader):    \n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = myModel(inputs)\n",
    "            cout = loss(outputs,labels.long())\n",
    "            v_cost += cout\n",
    "            _, predicted = torch.max(outputs.detach(), 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item() \n",
    "        v_cout_moy = v_cost/(len(train_loader))\n",
    "        accuracy = correct / total\n",
    "        print(accuracy)\n",
    "c_test = 0.0\n",
    "n_prev_c = 0\n",
    "with torch.no_grad():        \n",
    "    for i,(inputs,labels) in enumerate(test_loader):        \n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = myModel(inputs)\n",
    "            cout = loss(outputs,labels.long())\n",
    "            c_test += cout\n",
    "            _, predicted = torch.max(outputs.detach(), 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item() \n",
    "\n",
    "    c_test_moy = c_test/len(train_loader)\n",
    "\n",
    "\n",
    "    n_prev_cmoy = correct/total\n",
    "    print('test : '+ str(n_prev_cmoy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EpsImagePlugin.gs_windows_binary =  r'C:\\Program Files\\gs\\gs9.53.3\\bin\\gswin64c.exe'\n",
    "\n",
    "class main:\n",
    "    def __init__(self,master):\n",
    "        self.master = master\n",
    "        self.text = StringVar()\n",
    "        self.text.set('')\n",
    "        self.color_fg = 'white'\n",
    "        self.color_bg = 'black'\n",
    "        self.old_x = None\n",
    "        self.old_y = None\n",
    "        self.penwidth = 15\n",
    "        self.drawWidgets()\n",
    "        self.c.bind('<B1-Motion>',self.paint)\n",
    "        self.c.bind('<ButtonRelease-1>',self.reset)\n",
    "        frame = Frame(master)\n",
    "        frame.pack()\n",
    "        self.button = Button(frame,text=\"PREDICT\",fg=\"red\",command=self.predict)\n",
    "        self.button.pack(side=LEFT)\n",
    "        self.buttonclear = Button(frame,text=\"CLEAR\",fg=\"red\",command=self.clear)\n",
    "        self.buttonclear.pack(side=LEFT)\n",
    "        self.fontStyle =  tkFont.Font(family=\"Lucida Grande\", size=40)\n",
    "        self.label = Label(master, textvariable=self.text,font=self.fontStyle)\n",
    "\n",
    "        self.label.pack()\n",
    "\n",
    "\n",
    "    def paint(self,e):\n",
    "        if self.old_x and self.old_y:\n",
    "            self.c.create_line(self.old_x,\n",
    "                               self.old_y,\n",
    "                               e.x,\n",
    "                               e.y,\n",
    "                               width=self.penwidth,\n",
    "                               fill=self.color_fg,\n",
    "                               capstyle=ROUND,\n",
    "                               smooth=True)\n",
    "\n",
    "        self.old_x = e.x\n",
    "        self.old_y = e.y\n",
    "\n",
    "    def reset(self,e):    \n",
    "        self.old_x = None\n",
    "        self.old_y = None      \n",
    "\n",
    "    def clear(self):\n",
    "        self.c.delete(ALL)\n",
    "\n",
    "    def drawWidgets(self):\n",
    "\n",
    "        self.c = Canvas(self.master,width=500,height=500,bg=self.color_bg,highlightthickness=0)\n",
    "        self.c.pack(expand=False)\n",
    "\n",
    "\n",
    "    def predict(self) :\n",
    "        HWND = self.c.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "        with torch.no_grad():\n",
    "            output = myModel(feature_extraction(resize_image(im)).float())\n",
    "\n",
    "        self.text.set(str(int(torch.argmax(output))))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root = Tk()\n",
    "    main(root)\n",
    "    root.title('Application')\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(myModel.state_dict(), 'leModel100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(48, 100)\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "myModel=myNN()\n",
    "myModel.load_state_dict(torch.load('leModel100'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
